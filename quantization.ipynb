{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-16T08:10:38.337765Z",
     "end_time": "2023-05-16T08:10:38.354765Z"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "import torch\n",
    "from torch.ao.quantization import get_default_qconfig\n",
    "from torch.ao.quantization.quantize_fx import convert_fx, prepare_fx\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class MPJPELoss(nn.Module):\n",
    "    @staticmethod\n",
    "    def forward(pred_joints, y_joints):\n",
    "        x = torch.sum(pred_joints - y_joints, dim=-1)\n",
    "        distance_per_image = torch.mean(x.pow(2), dim=1)\n",
    "        return torch.mean(distance_per_image)\n",
    "\n",
    "class HandKeypointDetector(pl.LightningModule):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.backbone = MogaNet(\n",
    "            in_channels=3,\n",
    "            out_indices=[1, 2, 3],\n",
    "            depths=[3, 3, 10, 2],\n",
    "            widths=[32, 64, 96, 192],\n",
    "            stem_act_type='GELU',\n",
    "            stem_norm_type='LN',\n",
    "            moga_ratio=[1, 3, 4],\n",
    "            moga_dilations=[1, 2, 3],\n",
    "            drop_path_rate=0.1,\n",
    "            drop_rate=0.1,\n",
    "            ffn_scales=[8, 8, 4, 4],\n",
    "            ffn_act_type='GELU',\n",
    "            fd_act_type='GELU',\n",
    "            moga_act_type='SiLU'\n",
    "        )\n",
    "        self.head = TransformerFCN(\n",
    "            in_channels_layers=[[64, 96, 192], [108, 152, 144]],\n",
    "            fused_channels_layers=[[216, 304, 288], [-1, 368, 480]],\n",
    "            out_channels_layers=[[108, 152, 144], [108, 184, 240]],\n",
    "            depths_layers=[[3, 3, 3], [2, 3, 3]],\n",
    "            mlp_ratio_layers=[[4, 4, 4], [2, 2, 2]],\n",
    "            transformer_norm_type='LN',\n",
    "            mlp_drop_rate=0.1,\n",
    "            mlp_act_type='GELU',\n",
    "            attn_proj_act_type='ReLU',\n",
    "            attn_norm_type='LN',\n",
    "            drop_path_rate=0.1,\n",
    "            avg_pool_outputs=[2, 4, 6],\n",
    "            num_joints=21,\n",
    "            num_classes=0,\n",
    "        )\n",
    "        self.init_parameters()\n",
    "        self.config = config\n",
    "        self.save_hyperparameters()\n",
    "        self.criterion = torch.nn.L1Loss()\n",
    "        self.metric = MPJPELoss()\n",
    "\n",
    "    def init_parameters(self):\n",
    "        for name, m in self.named_modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, 0.00001, 1.0 / m.weight.shape[1])\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.00001)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0.0001)\n",
    "                nn.init.constant_(m.running_mean, 0)\n",
    "\n",
    "    def forward(self, images):\n",
    "        assert not torch.isnan(images).any(), 'Input creates nan'\n",
    "        img_features = self.backbone(images)\n",
    "        assert not torch.isnan(img_features[-1]).any(), 'Backbones creates nan'\n",
    "        outputs = self.head(img_features)\n",
    "        assert not torch.isnan(outputs).any(), 'Neck or Head creates nan'\n",
    "        return outputs\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), **self.config['optimizer'])\n",
    "        scheduler = CosineAnnealingWarmRestarts(optimizer, **self.config['scheduler'])\n",
    "        return [optimizer], [scheduler]\n",
    "\n",
    "    def _step(self, batch):\n",
    "        x, y = batch\n",
    "        assert not torch.isnan(y).any(), 'Input creates nan'\n",
    "        outputs = self.forward(x)\n",
    "        loss = self.criterion(outputs, y)\n",
    "        metric = self.metric(outputs, y)\n",
    "        assert not torch.isnan(loss).any(), 'Loss calculates nan'\n",
    "        return loss, metric\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        loss, metric = self._step(batch)\n",
    "        self.log(\"train_L1\", loss, sync_dist=True)\n",
    "        self.log(\"train_MPJPE\", metric, sync_dist=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # this is the validation loop\n",
    "        loss, metric = self._step(batch)\n",
    "        self.log(\"val_L1\", loss, sync_dist=True)\n",
    "        self.log(\"val_MPJPE\", metric, sync_dist=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # this is the test loop\n",
    "        loss, metric = self._step(batch)\n",
    "        self.log(\"test_L1\", loss, sync_dist=True)\n",
    "        self.log(\"test_MPJPE\", metric, sync_dist=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-16T08:10:38.668280Z",
     "end_time": "2023-05-16T08:10:38.692277Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "cannot instantiate 'PosixPath' on your system",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[19], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m fp32_model \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmodel_last.pt\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\hands-tracking\\lib\\site-packages\\torch\\serialization.py:809\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, **pickle_load_args)\u001B[0m\n\u001B[0;32m    807\u001B[0m             \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m    808\u001B[0m                 \u001B[38;5;28;01mraise\u001B[39;00m pickle\u001B[38;5;241m.\u001B[39mUnpicklingError(UNSAFE_MESSAGE \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(e)) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;28mNone\u001B[39m\n\u001B[1;32m--> 809\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _load(opened_zipfile, map_location, pickle_module, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[0;32m    810\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weights_only:\n\u001B[0;32m    811\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\hands-tracking\\lib\\site-packages\\torch\\serialization.py:1172\u001B[0m, in \u001B[0;36m_load\u001B[1;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001B[0m\n\u001B[0;32m   1170\u001B[0m unpickler \u001B[38;5;241m=\u001B[39m UnpicklerWrapper(data_file, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mpickle_load_args)\n\u001B[0;32m   1171\u001B[0m unpickler\u001B[38;5;241m.\u001B[39mpersistent_load \u001B[38;5;241m=\u001B[39m persistent_load\n\u001B[1;32m-> 1172\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43munpickler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1174\u001B[0m torch\u001B[38;5;241m.\u001B[39m_utils\u001B[38;5;241m.\u001B[39m_validate_loaded_sparse_tensors()\n\u001B[0;32m   1176\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\hands-tracking\\lib\\pickle.py:1212\u001B[0m, in \u001B[0;36m_Unpickler.load\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1210\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEOFError\u001B[39;00m\n\u001B[0;32m   1211\u001B[0m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, bytes_types)\n\u001B[1;32m-> 1212\u001B[0m         \u001B[43mdispatch\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1213\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m _Stop \u001B[38;5;28;01mas\u001B[39;00m stopinst:\n\u001B[0;32m   1214\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m stopinst\u001B[38;5;241m.\u001B[39mvalue\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\hands-tracking\\lib\\pickle.py:1589\u001B[0m, in \u001B[0;36m_Unpickler.load_reduce\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1587\u001B[0m args \u001B[38;5;241m=\u001B[39m stack\u001B[38;5;241m.\u001B[39mpop()\n\u001B[0;32m   1588\u001B[0m func \u001B[38;5;241m=\u001B[39m stack[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m-> 1589\u001B[0m stack[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\hands-tracking\\lib\\pathlib.py:1084\u001B[0m, in \u001B[0;36mPath.__new__\u001B[1;34m(cls, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1082\u001B[0m \u001B[38;5;28mself\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m_from_parts(args, init\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m   1083\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flavour\u001B[38;5;241m.\u001B[39mis_supported:\n\u001B[1;32m-> 1084\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcannot instantiate \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m on your system\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   1085\u001B[0m                               \u001B[38;5;241m%\u001B[39m (\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m,))\n\u001B[0;32m   1086\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init()\n\u001B[0;32m   1087\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "\u001B[1;31mNotImplementedError\u001B[0m: cannot instantiate 'PosixPath' on your system"
     ]
    }
   ],
   "source": [
    "fp32_model = torch.load('model_last.pt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# `qconfig` means quantization configuration, it specifies how should we\n",
    "# observe the activation and weight of an operator\n",
    "# `qconfig_dict`, specifies the `qconfig` for each operator in the model\n",
    "# we can specify `qconfig` for certain types of modules\n",
    "# we can specify `qconfig` for a specific submodule in the model\n",
    "# we can specify `qconfig` for some functioanl calls in the model\n",
    "# we can also set `qconfig` to None to skip quantization for some operators\n",
    "qconfig = get_default_qconfig(\"fbgemm\")\n",
    "qconfig_dict = {\"\": qconfig}\n",
    "# `prepare_fx` inserts observers in the model based on the configuration in `qconfig_dict`\n",
    "model_prepared = prepare_fx(model, qconfig_dict)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# calibration runs the model with some sample data, which allows observers to record the statistics of\n",
    "# the activation and weigths of the operators\n",
    "calibration_data = [torch.randn(1, 3, 224, 224) for _ in range(100)]\n",
    "for i in range(len(calibration_data)):\n",
    "   model_prepared(calibration_data[i])\n",
    "# `convert_fx` converts a calibrated model to a quantized model, this includes inserting\n",
    "# quantize, dequantize operators to the model and swap floating point operators with quantized operators\n",
    "model_quantized = convert_fx(copy.deepcopy(model_prepared))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# benchmark\n",
    "x = torch.randn(1, 3, 224, 224)\n",
    "%timeit fp32_model(x)\n",
    "%timeit model_quantized(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
